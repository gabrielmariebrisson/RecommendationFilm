import streamlit as st
import pandas as pd
import numpy as np
import tensorflow as tf
import pickle
import requests
from collections import defaultdict
from deep_translator import GoogleTranslator
import os
from dotenv import load_dotenv



load_dotenv()
API_KEY_FILM = os.getenv('API_KEY_FILM')
# --- Configuration de la traduction automatique ---
LANGUAGES = {
    "fr": "üá´üá∑ Fran√ßais",
    "en": "üá¨üáß English",
    "es": "üá™üá∏ Espa√±ol",
    "de": "üá©üá™ Deutsch",
    "it": "üáÆüáπ Italiano",
    "pt": "üáµüáπ Portugu√™s",
    "ja": "üáØüáµ Êó•Êú¨Ë™û",
    "zh-CN": "üá®üá≥ ‰∏≠Êñá",
    "ar": "üá∏üá¶ ÿßŸÑÿπÿ±ÿ®Ÿäÿ©",
    "ru": "üá∑üá∫ –†—É—Å—Å–∫–∏–π"
}

# Initialisation de la langue
if 'language' not in st.session_state:
    st.session_state.language = 'fr'

# S√©lecteur de langue
lang = st.sidebar.selectbox(
    "üåê Language / Langue", 
    options=list(LANGUAGES.keys()),
    format_func=lambda x: LANGUAGES[x],
    index=list(LANGUAGES.keys()).index(st.session_state.language)
)

st.session_state.language = lang

# Cache pour les traductions (√©vite de retranduire √† chaque fois)
if 'translations_cache' not in st.session_state:
    st.session_state.translations_cache = {}

def _(text):
    """Fonction de traduction automatique avec cache"""
    if lang == 'fr':
        return text
    
    # V√©rifier le cache
    cache_key = f"{lang}_{text}"
    if cache_key in st.session_state.translations_cache:
        return st.session_state.translations_cache[cache_key]
    
    # Traduire
    try:
        translated = GoogleTranslator(source='fr', target=lang).translate(text)
        st.session_state.translations_cache[cache_key] = translated
        return translated
    except:
        return text

# --- Fonctions de l'API OMDb ---
@st.cache_data(ttl=3600)
def get_movie_data(title):
    """R√©cup√®re les infos du film depuis OMDb"""
    year = None
    clean_title = title
    if title[-1] == ")" and "(" in title:
        try:
            year = title.split("(")[-1][:-1]
            clean_title = title.rsplit("(", 1)[0].strip()
        except:
            pass

    url = f"http://www.omdbapi.com/?t={clean_title}&apikey={API_KEY_FILM}"
    if year:
        url += f"&y={year}"

    try:
        response = requests.get(url).json()
        if response.get("Response") == "True":
            return {
                "title": response["Title"],
                "year": response["Year"],
                "genre": response.get("Genre", "N/A"),
                "director": response.get("Director", "N/A"),
                "actors": response.get("Actors", "N/A"),
                "plot": response.get("Plot", "N/A"),
                "rating": response.get("imdbRating", "N/A"),
                "votes": response.get("imdbVotes", "0"),
                "poster": response.get("Poster", None),
            }
    except requests.RequestException:
        return None
    return None

# --- Fonctions de chargement ---
@st.cache_resource
def load_model():
    try:
        def l2_norm(x):
            return tf.linalg.l2_normalize(x, axis=1)

        def diff_abs(x):
            return tf.abs(x[0] - x[1])

        def prod_mul(x):
            return x[0] * x[1]

        return tf.keras.models.load_model(
            "./templates/assets/film/best_model.keras",
            custom_objects={
                'l2_norm': l2_norm,
                'diff_abs': diff_abs,
                'prod_mul': prod_mul
            },
            safe_mode=False
        )
    except Exception as e:
        st.error(f"Erreur lors du chargement du mod√®le : {e}")
        return None

@st.cache_data
def load_objects():
    try:
        with open('./templates/assets/film/scalerUser.pkl', 'rb') as f: scalerUser = pickle.load(f)
        with open('./templates/assets/film/scalerItem.pkl', 'rb') as f: scalerItem = pickle.load(f)
        with open('./templates/assets/film/scalerTarget.pkl', 'rb') as f: scalerTarget = pickle.load(f)
        with open('./templates/assets/film/movie_dict.pkl', 'rb') as f: movie_dict = pickle.load(f)
        with open('./templates/assets/film/item_vecs_finder.pkl', 'rb') as f: item_vecs_finder = pickle.load(f)
        with open('./templates/assets/film/unique_genres.pkl', 'rb') as f: unique_genres = pickle.load(f)
        return scalerUser, scalerItem, scalerTarget, movie_dict, item_vecs_finder, unique_genres
    except FileNotFoundError:
        st.error(_("Fichiers .pkl manquants. Assurez-vous d'avoir ex√©cut√© le script de sauvegarde."))
        return (None,) * 6

# --- Fonction de recommandation ---
def generate_recommendations(model, user_ratings, scalers, data):
    scalerUser, scalerItem, scalerTarget = scalers
    movie_dict, item_vecs, unique_genres = data

    if not all([model, scalerUser, scalerItem, scalerTarget, movie_dict, item_vecs is not None, unique_genres]):
        return pd.DataFrame()

    num_ratings = len(user_ratings)
    avg_rating = np.mean(list(user_ratings.values()))
    genre_ratings = defaultdict(list)
    for movie_id, rating in user_ratings.items():
        genres_str = movie_dict[movie_id]['genres']
        if pd.notna(genres_str) and genres_str != "(no genres listed)":
            for genre in genres_str.split('|'):
                genre_ratings[genre].append(rating)

    user_prefs = {f'pref_{g}': np.mean(genre_ratings.get(g, [avg_rating])) for g in unique_genres}
    user_vec = np.array([[num_ratings, avg_rating, 0] + list(user_prefs.values())])
    
    num_items = len(item_vecs)
    user_vecs_repeated = np.tile(user_vec, (num_items, 1))

    suser_vecs = scalerUser.transform(user_vecs_repeated)
    sitem_vecs = scalerItem.transform(item_vecs[:, 1:])

    predictions = model.predict([suser_vecs, sitem_vecs])
    predictions_rescaled = scalerTarget.inverse_transform(predictions)

    recommendations = []
    for i, item_id in enumerate(item_vecs[:, 0]):
        if int(item_id) not in user_ratings:
            recommendations.append({
                'Movie ID': int(item_id),
                'Titre': movie_dict[int(item_id)]['title'],
                'Genres': movie_dict[int(item_id)]['genres'],
                'Note Pr√©dite': predictions_rescaled[i][0]
            })

    reco_df = pd.DataFrame(recommendations)
    return reco_df.sort_values(by='Note Pr√©dite', ascending=False)

# Bouton de redirection
st.markdown(
    f"""
    <a href="https://gabriel.mariebrisson.fr" target="_blank" style="text-decoration:none;">
    <div style="
    display: inline-block;
    background: linear-gradient(135deg, #6A11CB 0%, #2575FC 100%);
    color: white;
    padding: 12px 25px;
    border-radius: 30px;
    text-align: center;
    font-size: 16px;
    font-weight: 600;
    cursor: pointer;
    box-shadow: 0 4px 15px rgba(37, 117, 252, 0.3);
    transition: all 0.3s ease;
    text-transform: uppercase;
    letter-spacing: 1px;
    border: 2px solid transparent;
    position: relative;
    overflow: hidden;
    ">
    {_("Retour")}
    </div>
    </a>
    """,
    unsafe_allow_html=True
)

# --- Interface Streamlit ---
st.set_page_config(layout="wide", page_title=_("Cin√©-Reco"))
st.title(_("üé¨ Cin√©-Reco : Votre Guide Cin√©ma Personnalis√©"))

model = load_model()
scalerUser, scalerItem, scalerTarget, movie_dict, item_vecs_finder, unique_genres = load_objects()

if model and movie_dict:
    # --- Barre lat√©rale pour la notation ---
    st.sidebar.header(_("üîç Notez des films"))
    
    if 'user_ratings' not in st.session_state:
        st.session_state.user_ratings = {}

    # Recherche HORS du formulaire
    movie_list = sorted([info['title'] for info in movie_dict.values()])
    search_term = st.sidebar.text_input(_("Rechercher un film √† noter :"))
    
    if search_term:
        filtered_movie_list = [m for m in movie_list if search_term.lower() in m.lower()]
    else:
        filtered_movie_list = movie_list[:1000]

    with st.sidebar.form("rating_form"):
        if filtered_movie_list:
            selected_movie_title = st.selectbox(_("Choisissez un film"), filtered_movie_list)
        else:
            st.warning(_("Aucun film trouv√© avec cette recherche"))
            selected_movie_title = None
            
        rating = st.slider(_("Votre note"), 1.0, 5.0, 3.0, 0.5)
        submitted = st.form_submit_button(_("Ajouter la note"))

        if submitted and selected_movie_title:
            movie_id = next((mid for mid, info in movie_dict.items() if info['title'] == selected_movie_title), None)
            if movie_id:
                st.session_state.user_ratings[movie_id] = rating
                st.success(_("Note ajout√©e pour :") + f" {selected_movie_title}")

    if st.session_state.user_ratings:
        st.sidebar.subheader(_("Vos notes :"))
        for movie_id, rating in st.session_state.user_ratings.items():
            st.sidebar.write(f"- {movie_dict[movie_id]['title']}: **{rating} / 5.0**")
        if st.sidebar.button(_("üóëÔ∏è Vider les notes")):
            st.session_state.user_ratings = {}
            st.rerun()

    # --- Affichage principal des recommandations ---
    st.header(_("üåü Vos Recommandations Personnalis√©es"))
    if len(st.session_state.user_ratings) >= 3:
        with st.spinner(_("Nous pr√©parons votre s√©lection personnalis√©e...")):
            recommendations_df = generate_recommendations(
                model, 
                st.session_state.user_ratings,
                (scalerUser, scalerItem, scalerTarget),
                (movie_dict, item_vecs_finder, unique_genres)
            )
        
        all_genres = set()
        for genres_str in recommendations_df['Genres'].dropna():
            if genres_str and genres_str != "(no genres listed)":
                for genre in str(genres_str).split('|'):
                    if genre.strip():
                        all_genres.add(genre.strip())
        
        all_genres = sorted(list(all_genres))
        selected_genres = st.multiselect(_("Filtrer par genre :"), all_genres)
        
        if selected_genres:
            def has_selected_genre(genres_str):
                if pd.isna(genres_str) or not genres_str:
                    return False
                return any(g in str(genres_str) for g in selected_genres)
            
            filtered_df = recommendations_df[recommendations_df['Genres'].apply(has_selected_genre)]
        else:
            filtered_df = recommendations_df

        st.subheader(_("Top") + f" {min(20, len(filtered_df))} " + _("des films pour vous :"))
        
        cols = st.columns(5)
        for i, (idx, row) in enumerate(filtered_df.head(20).iterrows()):
            col = cols[i % 5]
            with col:
                movie_data = get_movie_data(row['Titre'])
                
                if movie_data and movie_data["poster"] and movie_data["poster"] != "N/A":
                    st.image(movie_data["poster"], caption=f"{row['Note Pr√©dite']:.1f} ‚≠ê")
                else:
                    st.image("./templates/assets/images/no-poster.jpg", caption=f"{row['Note Pr√©dite']:.1f} ‚≠ê")
                
                with st.expander(f"_{row['Titre']}_"):
                    st.write(f"**{_('Genres')} :** {movie_data['genre'] if movie_data else row['Genres']}")
                    st.write(f"**{_('Note pr√©dite')} :** {row['Note Pr√©dite']:.2f}")
                    if movie_data:
                        st.write(f"**{_('Acteurs')} :** {movie_data['actors']}")
                        st.write(f"**{_('R√©sum√©')} :** {movie_data['plot']}")
                        st.write(f"**{_('Note IMDb')} :** {movie_data['rating']} ‚≠ê")
                        st.write(f"**{_('Ann√©e')} :** {movie_data['year']}")

    else:
        st.info(_("""üëã Bienvenue !
Veuillez noter au moins 3 films dans la barre lat√©rale pour d√©bloquer vos recommandations.
Si on vous propose un film que vous avez d√©j√† vu, il suffit de le noter pour qu‚Äôil ne vous soit plus propos√©.
Si on vous propose de mauvais films, il suffit de leur mettre une mauvaise note."""))

    # Section Pr√©sentation
    st.header(_("Pr√©sentation"))
    st.markdown(_(
        """Ce projet vise √† recommander des films en fonction des notes attribu√©es par les utilisateurs. √Ä l'√®re du num√©rique, 
        les algorithmes de recommandation sont omnipr√©sents et jouent un r√¥le crucial dans nos choix quotidiens, en sugg√©rant 
        du contenu align√© avec nos pr√©f√©rences.

**Domaines d'application :**
- **E-commerce & Marketing :** Suggestion de produits similaires aux achats pr√©c√©dents pour augmenter les conversions
- **Services client :** Recommandation de services adapt√©s aux besoins identifi√©s de l'utilisateur
- **Divertissement :** Proposition de films, s√©ries ou musiques correspondant aux go√ªts de chacun
- **Analyse de tendances :** Identification de tendances √©mergentes bas√©es sur les comportements collectifs
- **Ressources humaines :** Mise en relation de profils compatibles (recrutement, networking)
- **√âducation :** Parcours d'apprentissage personnalis√©s selon le niveau et les centres d'int√©r√™t

**Donn√©es utilis√©es :**

Ce syst√®me s'appuie sur le jeu de donn√©es MovieLens, qui contient :
- **20 763 films** couvrant la p√©riode de 1874 √† 2024
- **8 493 utilisateurs** actifs
- **2 864 752 notes** au total (√©chelle de 0.5 √† 5 √©toiles)
- Donn√©es √† jour jusqu'au 1er mai 2024
- Multiples genres cin√©matographiques pour affiner les recommandations"""
    ))

    # Section Architecture du Mod√®le
    st.header(_("Architecture du Mod√®le"))
    st.markdown(_(
        """Notre syst√®me repose sur un **r√©seau de neurones siamois √† deux branches**, une architecture particuli√®rement 
        adapt√©e √† l'apprentissage de similarit√©s entre entit√©s h√©t√©rog√®nes.

**Structure du mod√®le :**

Le mod√®le est compos√© de deux sous-r√©seaux parall√®les :

1. **Branche utilisateur :** Transforme le profil utilisateur (historique de notes, pr√©f√©rences de genres) 
en une repr√©sentation vectorielle dense

2. **Branche film :** Encode les caract√©ristiques des films (genres, popularit√©, patterns de notation) 
dans un espace latent commun

**Composants techniques :**
- **Couches denses successives** (256 ‚Üí 128 ‚Üí 64 neurones) pour l'extraction de features hi√©rarchiques
- **Activation GELU** : Fonction d'activation continue favorisant une meilleure propagation du gradient
- **Normalisation par batch** : Stabilise l'apprentissage et acc√©l√®re la convergence
- **Dropout (30%)** : Pr√©vient le surapprentissage en d√©sactivant al√©atoirement certains neurones
- **R√©gularisation L2 (1e-6)** : P√©nalise les poids √©lev√©s pour favoriser la g√©n√©ralisation
- **Normalisation L2 finale** : Projette les embeddings sur une hypersph√®re unitaire pour des comparaisons stables

**Couche de fusion :**

Les vecteurs normalis√©s sont combin√©s via deux op√©rations compl√©mentaires :
- **Diff√©rence absolue** : Capture la dissimilarit√© entre utilisateur et film
- **Produit √©l√©ment par √©l√©ment** : Mod√©lise la similarit√© bilin√©aire et les interactions fines

**Pr√©diction finale :**

Une couche Dense avec activation sigmo√Øde produit un score de compatibilit√© entre 0 et 1, 
facilement convertible en note pr√©dite sur l'√©chelle 0.5-5 √©toiles.

**Limitations connues :**
- Pas de prise en compte des donn√©es textuelles (synopsis, critiques)
- L'ordre chronologique des notes n'est pas exploit√©
- Les √©volutions temporelles des pr√©f√©rences ne sont pas mod√©lis√©es

Malgr√© ces limitations, le mod√®le offre des recommandations fiables et pertinentes."""
    ))
    st.image("./templates/assets/film/architecture_model.png", caption=_("Architecture du mod√®le neuronal"), use_container_width=True)

    # Section R√©sultats
    st.header(_("Performances du Mod√®le"))
    st.markdown(_(
        """**Capacit√©s du syst√®me :**

Le mod√®le entra√Æn√© permet deux types d'utilisation :
1. **Pr√©diction de note** : Estimer la note qu'un utilisateur attribuerait √† un film non vu
2. **Recommandation personnalis√©e** : Sugg√©rer les films avec les meilleures notes pr√©dites pour un utilisateur donn√©

**M√©triques de performance :**
- **RMSE (Root Mean Square Error) : 0.35** - Erreur moyenne de pr√©diction
- **MSE (Mean Square Error) : 0.12** - M√©trique d'optimisation du mod√®le

Ces r√©sultats sont satisfaisants pour un syst√®me de recommandation : une erreur de ~0.35 √©toile 
repr√©sente une pr√©cision acceptable dans la pr√©diction des pr√©f√©rences cin√©matographiques.

√Ä titre de comparaison, les syst√®mes de recommandation professionnels atteignent g√©n√©ralement des RMSE 
entre 0.25 et 0.40 sur MovieLens, positionnant notre mod√®le dans une fourchette comp√©titive."""
    ))

    # Section Co√ªt et Maintenance
    st.header(_("D√©veloppement et D√©ploiement"))
    st.markdown(_(
        """**Infrastructure d'entra√Ænement :**
- Mat√©riel utilis√© : MacBook M1 (sans GPU d√©di√©)
- Temps de pr√©paration des donn√©es : ~30 minutes
- Dur√©e d'entra√Ænement : 35 minutes
- Co√ªt total : 0‚Ç¨ (aucune ressource cloud n√©cessaire)

**Caract√©ristiques du mod√®le en production :**
- Taille du mod√®le : 1.8 Mo (d√©ploiement l√©ger)
- Temps d'inf√©rence : < 1 seconde pour g√©n√©rer des recommandations
- Scalabilit√© : Compatible avec des environnements √† ressources limit√©es

**Co√ªts op√©rationnels :**
- **Entra√Ænement** : Gratuit (CPU standard suffisant)
- **H√©bergement** : Minimal (faible empreinte m√©moire)
- **Maintenance** : Mise √† jour p√©riodique du dataset et r√©entra√Ænement occasionnel

**Axes d'am√©lioration futurs :**
- Int√©gration de donn√©es textuelles (NLP sur synopsis et critiques)
- Prise en compte de la dimension temporelle (√©volution des go√ªts)
- Ajout de features contextuelles (heure, dispositif, m√©t√©o)
- Mod√®le hybride combinant filtrage collaboratif et approche content-based
- A/B testing pour optimiser les hyperparam√®tres en production
- Explainability : visualisation des facteurs influen√ßant chaque recommandation"""
    ))



else:
    st.error(_("L'application n'a pas pu d√©marrer. V√©rifiez les fichiers du mod√®le et des donn√©es."))

# Footer
st.markdown("---")
st.markdown(_(
    """
    D√©velopp√© par [Gabriel Marie-Brisson](https://gabriel.mariebrisson.fr)
    """
))